# Text Generation Using GPT-2
#### prerequisites
- **Attention RNN**: [Attention RNN](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- **Transformers**: [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) by @JayAlammar(twitter)
- **GPT-2**:
