{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hackernoon.com/no-code-needs-to-adapt-to-specialists-an-argument-uo1w328p    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 2.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from transformers) (1.17.2)\n",
      "Requirement already satisfied: filelock in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers==0.9.4 (from transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ec/6d009ff69a9fdc2debab4a8f6c3e47afebb505bdea335187bc0bbf4a618f/tokenizers-0.9.4-cp37-cp37m-macosx_10_11_x86_64.whl (2.0MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 4.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17 (from transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/d5/ae173868b6525c6f18f9a684c8842c0673cfc630430fcb48d8c6eb817f2e/regex-2020.11.13-cp37-cp37m-macosx_10_9_x86_64.whl (284kB)\n",
      "\u001b[K     |████████████████████████████████| 286kB 2.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from transformers) (19.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from transformers) (4.54.1)\n",
      "Requirement already satisfied: requests in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from transformers) (2.24.0)\n",
      "Collecting sacremoses (from transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 778kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from packaging->transformers) (2.4.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: click in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893261 sha256=c4d19e6952b5cb88eb21ad77fdd3fed5181776641abd35c226776dd0a53eeca1\n",
      "  Stored in directory: /Users/nicholasrenotte/Library/Caches/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, regex, sacremoses, transformers\n",
      "Successfully installed regex-2020.11.13 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'YouTube Title: AI learns to'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33869, 11851,    25,  9552, 22974,   284]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "output = model.generate(input_ids, max_length=50, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33869, 11851,    25,  9552, 22974,   284,   711,  2008,  1830,   198,\n",
       "           198, 13838,    25,   575,  1236,  1004,    34,   403,    11,  2059,\n",
       "           286,  3442,    11,  2986,  9500,    11,  4916,   628,   198, 11280,\n",
       "            25,  2638,  1378,   283,    87,   452,    13,  2398,    14,  8937,\n",
       "            14,  1433,  1157,    13,  2713,    23,  2481,   198,    11,   198]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube Title: AI learns to play video games\n",
      "\n",
      "Author: Yann LeCun, University of California, San Diego, USA\n",
      "\n",
      "\n",
      "Link: http://arxiv.org/abs/1611.05821\n",
      ",\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
